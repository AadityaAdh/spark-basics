{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b36e892b-f394-4c57-b5df-92b1ad1b0912",
   "metadata": {},
   "source": [
    "Sure! Here's a straightforward explanation of **schema in Spark**:\n",
    "\n",
    "---\n",
    "\n",
    "### What is a **Schema** in Spark?\n",
    "\n",
    "* A **schema** defines the **structure of a DataFrame** â€” like a blueprint describing:\n",
    "\n",
    "  * **Column names**\n",
    "  * **Data types** of each column (e.g., String, Integer, Date)\n",
    "  * Whether columns can be **nullable** or not\n",
    "\n",
    "---\n",
    "\n",
    "### Why is schema important?\n",
    "\n",
    "* It tells Spark **how to interpret the data**.\n",
    "* Enables **efficient querying and optimization** via Spark's Catalyst engine.\n",
    "* Ensures **data consistency and validation**.\n",
    "* Allows Spark to **store data in a structured format** instead of raw bytes.\n",
    "\n",
    "---\n",
    "\n",
    "### How to define a schema?\n",
    "\n",
    "You can let Spark **infer schema automatically** (e.g., when reading CSV/JSON with `inferSchema=True`), or you can define it **explicitly**.\n",
    "\n",
    "---\n",
    "\n",
    "### Example: Defining a schema explicitly\n",
    "\n",
    "```python\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), False)  # False means non-nullable\n",
    "])\n",
    "\n",
    "data = [(\"Alice\", 25), (\"Bob\", 30)]\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.printSchema()\n",
    "df.show()\n",
    "```\n",
    "\n",
    "**Output of `printSchema()`:**\n",
    "\n",
    "```\n",
    "root\n",
    " |-- name: string (nullable = true)\n",
    " |-- age: integer (nullable = false)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### How to see the schema of a DataFrame?\n",
    "\n",
    "Use:\n",
    "\n",
    "```python\n",
    "df.printSchema()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary:\n",
    "\n",
    "| Term        | Description                                   |\n",
    "| ----------- | --------------------------------------------- |\n",
    "| Schema      | Structure: column names & types               |\n",
    "| StructType  | Container for a list of fields                |\n",
    "| StructField | Defines a single field (name, type, nullable) |\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can also help explain how Spark uses schema to optimize queries or how to work with complex nested schemas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5e2d09-4171-4d87-b772-ffb21e6a2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=U3sgM-ohLVE&list=PLTsNSGeIpGnGjaMSYVlidqVWSjKWoBhbr&index=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e9f8f-362b-4638-a6d7-c3ad5f93ec41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
